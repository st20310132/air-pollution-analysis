{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1mTTScFrZjuuOiC1PTrZPP__2a9kvNqWT",
      "authorship_tag": "ABX9TyPrlwI26fWqlj0Z+FgPzXtn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/st20310132/air-pollution-analysis/blob/main/CMP7005.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayaWQnqv6zBo",
        "outputId": "d359c032-65a0-413b-fbfd-07322f663cc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loaded urban site: Dongsi - Shape: (35064, 18)\n",
            "Loaded suburban site: Shunyi - Shape: (35064, 18)\n",
            "Loaded rural site: Dingling - Shape: (35064, 18)\n",
            "Loaded industrial site: Gucheng - Shape: (35064, 18)\n",
            "\n",
            "Merged Dataset Shape: (140256, 20)\n",
            "\n",
            "First 5 rows of the merged dataset:\n",
            "   No  year  month  day  hour  PM2.5  PM10  SO2   NO2     CO    O3  TEMP  \\\n",
            "0   1  2013      3    1     0    9.0   9.0  3.0  17.0  300.0  89.0  -0.5   \n",
            "1   2  2013      3    1     1    4.0   4.0  3.0  16.0  300.0  88.0  -0.7   \n",
            "2   3  2013      3    1     2    7.0   7.0  NaN  17.0  300.0  60.0  -1.2   \n",
            "3   4  2013      3    1     3    3.0   3.0  5.0  18.0    NaN   NaN  -1.4   \n",
            "4   5  2013      3    1     4    3.0   3.0  7.0   NaN  200.0  84.0  -1.9   \n",
            "\n",
            "     PRES  DEWP  RAIN   wd  WSPM station site_type site_name  \n",
            "0  1024.5 -21.4   0.0  NNW   5.7  Dongsi     urban    Dongsi  \n",
            "1  1025.1 -22.1   0.0   NW   3.9  Dongsi     urban    Dongsi  \n",
            "2  1025.3 -24.6   0.0  NNW   5.3  Dongsi     urban    Dongsi  \n",
            "3  1026.2 -25.5   0.0    N   4.9  Dongsi     urban    Dongsi  \n",
            "4  1027.1 -24.5   0.0  NNW   3.2  Dongsi     urban    Dongsi  \n",
            "\n",
            "Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 140256 entries, 0 to 140255\n",
            "Data columns (total 20 columns):\n",
            " #   Column     Non-Null Count   Dtype  \n",
            "---  ------     --------------   -----  \n",
            " 0   No         140256 non-null  int64  \n",
            " 1   year       140256 non-null  int64  \n",
            " 2   month      140256 non-null  int64  \n",
            " 3   day        140256 non-null  int64  \n",
            " 4   hour       140256 non-null  int64  \n",
            " 5   PM2.5      137168 non-null  float64\n",
            " 6   PM10       138118 non-null  float64\n",
            " 7   SO2        137060 non-null  float64\n",
            " 8   NO2        135388 non-null  float64\n",
            " 9   CO         131468 non-null  float64\n",
            " 10  O3         136160 non-null  float64\n",
            " 11  TEMP       140081 non-null  float64\n",
            " 12  PRES       140085 non-null  float64\n",
            " 13  DEWP       140078 non-null  float64\n",
            " 14  RAIN       140091 non-null  float64\n",
            " 15  wd         139396 non-null  object \n",
            " 16  WSPM       140113 non-null  float64\n",
            " 17  station    140256 non-null  object \n",
            " 18  site_type  140256 non-null  object \n",
            " 19  site_name  140256 non-null  object \n",
            "dtypes: float64(11), int64(5), object(4)\n",
            "memory usage: 21.4+ MB\n",
            "\n",
            "Missing Values Count:\n",
            "No              0\n",
            "year            0\n",
            "month           0\n",
            "day             0\n",
            "hour            0\n",
            "PM2.5        3088\n",
            "PM10         2138\n",
            "SO2          3196\n",
            "NO2          4868\n",
            "CO           8788\n",
            "O3           4096\n",
            "TEMP          175\n",
            "PRES          171\n",
            "DEWP          178\n",
            "RAIN          165\n",
            "wd            860\n",
            "WSPM          143\n",
            "station         0\n",
            "site_type       0\n",
            "site_name       0\n",
            "dtype: int64\n",
            "\n",
            "Merged dataset saved to: /content/drive/MyDrive/Colab_Notebooks/merged_air_quality_data.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# For better visualization\n",
        "plt.style.use('seaborn-v0_8-whitegrid')  # Updated seaborn style name\n",
        "sns.set_style(\"whitegrid\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Define the path to your CSV files\n",
        "# Replace with your actual path to the folder containing the CSV files\n",
        "data_path = '/content/drive/MyDrive/Colab_Notebooks'\n",
        "\n",
        "# Step 3: Select and read datasets from different site types\n",
        "sites = {\n",
        "    'urban': 'Dongsi',\n",
        "    'suburban': 'Shunyi',\n",
        "    'rural': 'Dingling',\n",
        "    'industrial': 'Gucheng'\n",
        "}\n",
        "\n",
        "dfs = {}\n",
        "for area_type, site in sites.items():\n",
        "    # Look for files containing the site name\n",
        "    file_pattern = f\"*{site}*.csv\"\n",
        "    matching_files = [f for f in os.listdir(data_path) if site in f and f.endswith('.csv')]\n",
        "\n",
        "    if matching_files:\n",
        "        file_name = matching_files[0]  # Take the first matching file\n",
        "        file_path = os.path.join(data_path, file_name)\n",
        "        dfs[area_type] = pd.read_csv(file_path)\n",
        "        print(f\"Loaded {area_type} site: {site} - Shape: {dfs[area_type].shape}\")\n",
        "    else:\n",
        "        print(f\"No file found for {area_type} site: {site}\")\n",
        "\n",
        "# Step 4: Add columns to identify the site type\n",
        "for area_type, df in dfs.items():\n",
        "    df['site_type'] = area_type\n",
        "    df['site_name'] = sites[area_type]\n",
        "\n",
        "# Step 5: Merge all datasets\n",
        "if dfs:\n",
        "    merged_df = pd.concat(dfs.values(), ignore_index=True)\n",
        "    print(\"\\nMerged Dataset Shape:\", merged_df.shape)\n",
        "\n",
        "    # Display the first few rows\n",
        "    print(\"\\nFirst 5 rows of the merged dataset:\")\n",
        "    print(merged_df.head())\n",
        "\n",
        "    # Basic information about the merged dataset\n",
        "    print(\"\\nDataset Information:\")\n",
        "    merged_df.info()\n",
        "\n",
        "    # Check for missing values\n",
        "    print(\"\\nMissing Values Count:\")\n",
        "    print(merged_df.isnull().sum())\n",
        "\n",
        "    # Save the merged dataset for future use\n",
        "    merged_file_path = os.path.join(data_path, 'merged_air_quality_data.csv')\n",
        "    merged_df.to_csv(merged_file_path, index=False)\n",
        "    print(f\"\\nMerged dataset saved to: {merged_file_path}\")\n",
        "else:\n",
        "    print(\"No datasets were loaded. Please check file names and try again\")"
      ]
    }
  ]
}